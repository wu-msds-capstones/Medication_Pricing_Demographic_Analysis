---
title: "Drug Pharmacy Costs Across US Demographics"
subtitle: |
  ![](images/W_compass.png){height=0.5in}
  Data Science Capstone
authors: "Ellann Cohen and Travis McKenzie"
bibliography: references.bib
title-block-banner: true
format: 
  html:
    theme:
      light: lightly
      dark: darkly
    title-block-banner: linear-gradient(45deg, rgb(186, 12, 47) 0%, rgb(0,0,0) 100%);
    title-block-banner-color: "#D8DEE9"
runtime: shiny
---

# Introduction

Escalating pharmaceutical prices in the U.S. are reshaping public health policy, widening healthcare disparities, and straining the financial well-being of millions. A recent KFF poll found that 60% of adults take at least one prescription, and 25% take four or more [@KFF2024]. Yet, as pharmaceutical technology advances, affordability remains a significant concern. Even with coverage through Medicare, Medicaid, or private insurance, many patients face high out-of-pocket costs that contribute to financial stress and, in some cases, treatment avoidance. 

According to the Commonwealth Fund [@TCF2025], 30% of U.S. adults carry medical debt, and nearly 57% of underinsured adults delay or avoid necessary treatment due to cost. This financial strain is compounded by the fragmented structure of public insurance programs like Medicare and Medicaid, which serve only specific populations and vary widely by state and county. These regional differences in plan availability and coverage often translate into significant disparities in pricing and out-of-pocket costs, further undermining equitable access to care.

While medications are only one aspect of medical care, they are essential in preventing more costly interventions. Chronic conditions such as diabetes, cardiovascular disease, and kidney disease can often be effectively managed with medication, reducing the need for hospitalization or surgery. A recent study by UNC Health [@unc2025semaglutide] found that oral semaglutide (marketed as Ozempic and Rybelsus for diabetes, and Wegovy for weight loss) significantly lowered the risk of heart attacks and strokes. This underscores that medication affordability is not merely a matter of convenience but a foundation of equitable, cost-effective healthcare.

This project examines the costs associated with Medicare prescription drug plans and their impact on different demographic groups across the U.S. By analyzing how plan pricing varies by state and county, we aim to better understand the financial burden on underserved populations. The findings will illuminate geographic and socioeconomic disparities in medication affordability and may inform policy changes or targeted interventions to advance health equity.

To support this analysis, we integrated publicly available data from the Centers for Medicare & Medicaid Services (CMS), the U.S. Census Bureau, and the Food and Drug Administration (FDA). These datasets provide detailed information on drug pricing, clinical use, demographic characteristics, and public insurance coverage specifically for Medicare patients (aka patients over the age of 65).  We consolidated the data into a unified DuckDB instance hosted on AWS S3, enabling efficient, scalable querying across the large and diverse datasets. This infrastructure underpins a comprehensive analysis of pharmaceutical spending and supports demographically informed cost modeling.



# Background and Data Collection

## Data sources

For data collection, our first focus was on collecting pricing information for different drugs tied to different geographic locations so we could easily pair those geographic locations with demographic census data. 

To obtain medication pricing data, we initially explored several APIs from online pharmacies, including GoodRx [@goodrx2025], which aim to improve consumer price transparency. However, these sources could not be reliably linked to the county-level demographic data essential to our analysis. Consequently, we turned to the Centers for Medicare & Medicaid Services (CMS), which offers one of the most comprehensive public datasets on healthcare coverage and drug pricing. CMS maintains over 100 datasets spanning prescription costs, plan structures, and beneficiary demographics [@cms2025data].

Among the available CMS datasets, we selected the Quarterly Prescription Drug Plan Formulary as our primary source. Of particular interest were the pricing files, basic formulary files, plan information files, and the geographic locator file, which enabled us to map drug prices and plan availability at the county level across the U.S. A key limitation of this dataset is that it reflects only those covered under Medicare, which applies to a specific segment of the population. Medicare eligibility generally requires individuals to be age 65 or older, although those with disabilities, end-stage renal disease (ESRD), or amyotrophic lateral sclerosis (ALS) may qualify earlier [@medicareEligibility]. Despite this limitation, Medicare formulary data, specifically Part D coverage, can serve as a functional proxy for medication prices across the US.  First, Medicare Part D covers over 50 million beneficiaries, which makes it one of the largest prescription drug programs in the US.  Medicare contracts with private insurers who then negotiate prices with drug manufacturers and pharmacies, which can reflect real-world pricing.  Medicare has tremendous leverage in the marketplace and is one of the largest purchasers of prescription drugs.  Accordingly, this makes Medicare a substantial market influencer, which means that its pricing can set or anchor prices for the entire marketplace.  We can reasonably infer that uninsured buyers, or buyers leveraging other forms of insurance, would pay at least as much as Medicare under Part D coverage.  

In conclusion, the formulary dataset offered a rare combination of granularity and breadth, with plan- and region-specific pricing that could be meaningfully paired with demographic data. It was also readily accessible and downloadable in bulk, making it a practical and robust foundation for our analysis.

The demographic data selection was much simpler, and we quickly concluded that the US Census [@uscensus2025] would provide county-level demographic information, which we could connect to the medication pricing data after only a little data cleaning. Our team leveraged the Tidycensus [@tidycensus2025] package in R to ingest demographic data at the county level.

During initial exploration, we found that the CMS datasets reference medications only by their National Drug Code (NDC), without corresponding drug names. To interpret these codes meaningfully, we integrated drug identification data from the FDA’s National Drug Code Directory [@fda2025ndc].
Finally, we incorporated three additional datasets from CMS to assess overall drug spending at the national level. These datasets, covering the years 2019 through 2023, provided high-level insights into Medicare and Medicaid expenditures, including spending under Medicare Part D, Medicare Part B, and Medicaid. While this data lacked the geographic granularity needed for county-level analysis, it offered valuable context by identifying medications with the greatest national impact based on total cost.
This broader perspective helped inform and prioritize our exploration of the formulary data. The national spending datasets included information on total spending, the number of beneficiaries, claims filed, and doses dispensed. This enabled us to assess patterns such as high-cost, low-frequency medications versus low-cost, high-frequency ones. Integrating this information into our broader database enhanced analytical flexibility and supported a more comprehensive understanding of pharmaceutical spending across programs.

## Data cleaning

Although the previous section may suggest that combining and storing the data was straightforward, the data cleaning and processing phase presented a significant challenge, consistent with the complexities typical of most data science projects.  Below, we outline several key issues encountered during this stage.

The CMS Quarterly Prescription Drug Plan Formulary datasets were significantly larger than those our team had previously worked with. Each quarterly file from 2019 Q1 through 2025 Q1 contained approximately 10–12 GB of compressed data. To manage scope, we narrowed our focus to the 2023 Q4 dataset. Even within this single quarter, the formulary included pricing data for approximately 6,336 unique medications (identified by NDC codes), across multiple dosage strengths and 30-, 60-, and 90-day supply options. These were distributed across 5,644 unique contract/plan combinations.
Some Medicare plan options were listed at the county level, while others were available only at the broader regional level, either as Medicare Advantage (MA, also known as Part C) or Prescription Drug Plans (PDP). To align these regional plans with our census-based demographic data, we disaggregated them by county. Medication prices varied not only by NDC code, but also by supply duration, dosage strength (e.g., 10 mg, 30 mg, 50 mg daily), delivery mechanism (e.g., pill, patch, injection, liquid), and Medicare plan.

A major limitation of the CMS formulary data was the absence of medication names; it included only 11-digit National Drug Code (NDC) identifiers. In contrast, the overall spending dataset listed drug names but did not include NDC codes, making it impossible to directly join the two datasets without an intermediary reference. Because NDC codes are not interpretable to non-experts, converting them to medication names was essential for meaningful analysis and presentation.

To resolve this, we turned to the FDA’s National Drug Code Directory [@fda2025ndc], which provides comprehensive drug identification data. However, we encountered a formatting mismatch: the NDC codes in the FDA dataset included dashes and excluded leading zeros, resulting in codes shorter than the 11-digit format used by CMS. The NDC structure consists of three segments (labeler (5 digits), product (4 digits), and package (2 digits)), but the FDA format often compresses these fields, creating inconsistencies once the dashes are removed.
To reconcile this, we standardized both datasets to a 9-digit format by removing the package-level detail and padding or trimming segments as needed. After extensive data cleaning and formatting, we successfully linked the FDA drug names to the CMS formulary data, enabling consistent identification and analysis across datasets.

Fortunately, the naming conventions utilized by CMS in their overall spending data were largely consistent with the naming conventions provided by the FDA (95% match), which allowed for the overall spending files to be related in the database to individual medication prices by county and Medicare plan.  The project now had compelling connections across a massive number of very large data files. 

During the geographic analysis, we identified a unique complication related to Connecticut. In 2022, all Connecticut counties were renamed and had their boundaries redrawn [@countiesConnecticut]. While our primary focus was on Q4 2023 data, a discrepancy emerged: CMS data continued to use the pre-2022 county names and boundaries, whereas the U.S. Census Bureau adopted the updated designations. Because the county shapes also changed, we applied engineering judgment to map the old county definitions to the new ones. As a result, any county-level analysis for Connecticut should be interpreted as an approximation. Data for all other U.S. counties remains accurate once spellings were matched.

# Data Engineering

From the outset, the project faced substantial challenges in gathering and assembling the data, chief among them, the scale and accessibility of the files. The volume of data, which exceeded 100 GB compressed (nearly 300 GB uncompressed), far surpassed the file size limitations imposed by GitHub. While GitHub does offer a Large File Storage (LFS) extension, it was not sufficient for the scope of this project. Moreover, the team needed a collaborative environment where all members could access, modify, and validate shared datasets without working in silos, which could risk data inconsistency.

To address this, and upon the recommendation of Professor Jed Rembold, we explored several cloud storage options, including Microsoft Azure Blob Storage, Google Cloud Storage, and Amazon Web Services (AWS) S3 (Simple Storage Service). After evaluating the alternatives, AWS S3 was selected for its flexibility, scalability, and broad support within the data science community. Using S3, we created a centralized, cloud-based storage system that allowed team members to upload, retrieve, and organize large datasets seamlessly.

Implementing this solution was not trivial. Neither team member had prior experience with AWS, and the learning curve was significant. However, support from large language models (LLMs) such as GitHub Copilot and ChatGPT proved instrumental in navigating technical setup, access permissions, and authentication token generation. Additionally, AWS’s built-in LLM support further streamlined the configuration and administration process. The result was a robust, scalable storage infrastructure that underpinned our data pipeline and enabled consistent access and collaboration throughout the project.

Setting up the AWS S3 bucket was only the first step in implementing a robust data infrastructure. Professor Rembold also recommended using DuckDB, an in-process SQL OLAP (Online Analytical Processing) database designed for high-performance analytical queries on large datasets. Unlike traditional database systems, DuckDB operates without a dedicated server, making it ideal for decentralized, collaborative data science workflows.
A third critical recommendation was to convert all raw data, originally provided in CSV and text formats by CMS, the FDA, and the U.S. Census Bureau, into Parquet, a columnar storage format optimized for analytical workloads. Parquet offers efficient compression and schema evolution, and it integrates seamlessly with DuckDB. By adopting Parquet, we reduced storage costs and improved query speed, allowing us to manage and process the dataset more effectively within the AWS S3 environment.

Together, AWS S3, DuckDB, and Parquet formed a cohesive, scalable solution. The team was able to interface with this infrastructure using R, enabling the creation of reusable scripts that could be stored and version-controlled in GitHub. This structure supported asynchronous collaboration, ensured data consistency, and also allowed us to explore advanced features of RStudio, particularly its GitHub integration.
Over 100 Parquet files were ultimately stored in the AWS S3 bucket, many representing variations of plan files, geographic locator files, drug formulary files, and pricing data from the CMS Quarterly Prescription Drug Plan Formulary dataset. While not all files were used in the final analysis, early-stage exploration required access to every quarter from 2019 to 2023. In contrast, the U.S. Census, FDA NDC, and CMS spending datasets were far smaller and could have been managed locally. However, the CMS formulary data’s size and complexity made scalable storage essential. Though it introduced some engineering challenges, using S3 was ultimately the right choice—it enabled the creation of a structured, relational database across a large, disparate dataset.

We adopted an ELT (Extract, Load, Transform) approach. Data was first extracted from the original sources and loaded into the S3 bucket, which functioned as a centralized data warehouse. From there, transformation and analysis occurred via scripts written in R, using DuckDB’s SQL-based query functions to interface with the Parquet files. These scripts were version-controlled in GitHub, allowing both team members to collaborate asynchronously while maintaining consistency and reproducibility. This architecture enabled scalable, iterative analysis and fostered a cohesive workflow for generating insights.

Thanks to the data cleaning process, which standardized NDC formats across CMS and FDA datasets, we were able to join medication identifiers consistently across data sources. This enabled reliable mapping between county-level pricing data, national spending records, and drug names—critical for conducting meaningful demographic and geographic analysis.
By the end of the data engineering phase, our team had established a fully connected data architecture. We could now relate county-level U.S. Census demographic data to CMS Medicare Part D formulary pricing, map those prices to specific NDC codes, and link them to national spending data from CMS. This structured, relational framework enabled aggregation, comparison, and exploration of how medication pricing impacts different demographic groups across the U.S.

# Analysis

## Scope of Analysis:
One of the first goals was to understand the connected data at a high level by condensing and aggregating details. Due to the granularity of the formulary data, it was necessary to narrow the focus rather than analyze all 6,000+ medications. The CMS spending datasets (Part B, Part D, and Medicaid) provided a clearer, structured view and helped identify high-impact drugs. Using this data, we generated top drug lists by total spend, claims, and doses (@fig-topspend), ultimately selecting a few key medications for deeper analysis.
 
**TRAVIS TO UPDATE THIS PLOT WITH CODE**

![Top drugs by absolute Medicare spending in 2023](./images/Top_Spend.jpg){#fig-topspend}
For the rest of the analysis, we plan to use these top drugs by the most absolute spend in 2019-2023. To help contextualize what these medications treat, see the table below. 

| Medication Generic Name | Brand Name(s)            | Common Conditions                                                                                                         | Total Spend (USD) |
|------------------------|--------------------------|--------------------------------------------------------------------------------------------------------------------------|------------------|
| Apixaban               | Eliquis                  | AFib (Atrial Fibrillation), DVT/PE (Deep Vein Thrombosis / Pulmonary Embolism), Post-surgery Prophylaxis                   | $67.3B           |
| Adalimumab             | Humira, Biosimilars      | Chronic inflammatory or autoimmune conditions such as RA (Rheumatoid Arthritis), PsA (Psoriatic Arthritis), AS (Ankylosing Spondylitis), CD (Crohn’s Disease), UC (Ulcerative Colitis), Psoriasis, JIA (Juvenile Idiopathic Arthritis), Uveitis | $43.1B           |
| Dulaglutide            | Trulicity                | Type 2 Diabetes                                                                                                           | $30.9B           |
| Lenalidomide           | Revlimid                 | Multiple Myeloma, MDS (Myelodysplastic Syndromes)                                                                          | $29.9B           |
| Rivaroxaban            | Xarelto                  | AFib (Atrial Fibrillation), DVT/PE (Deep Vein Thrombosis / Pulmonary Embolism)                                            | $28.4B           |
| Empagliflozin          | Jardiance                | Type 2 Diabetes, CV risk                                                                                                   | $26.9B           |
| Semaglutide            | Ozempic, Wegovy          | Type 2 Diabetes, Obesity                                                                                                   | $26.7B           |
| Paliperidone Palmitate | Invega Sustenna, Trinza  | Schizophrenia                                                                                                             | $18.4B           |
| Etanercept             | Enbrel                   | RA (Rheumatoid Arthritis), PsA (Psoriatic Arthritis), AS (Ankylosing Spondylitis), Psoriasis                              | $16.7B           |
| Insulin Aspart         | Novolog, Fiasp           | Type 1 & 2 Diabetes                                                                                                        | $15.7B           |
| Ustekinumab            | Stelara                  | Psoriasis, PsA (Psoriatic Arthritis), Crohn’s Disease                                                                      | $15.2B           |
| Ibrutinib              | Imbruvica                | Blood cancers such as CLL (Chronic Lymphocytic Leukemia), MCL (Mantle Cell Lymphoma), and WM (Waldenström's Macroglobulinemia) | $14.5B           |
| Tiotropium Bromide     | Spiriva                  | COPD (Chronic Obstructive Pulmonary Disease), Asthma (adjunct)                                                            | $12.1B           |
| Liraglutide            | Victoza, Saxenda         | Type 2 Diabetes, Obesity                                                                                                   | $11.6B           |



## Overview of Analysis:
Afte mapping individual medication prices to counties across the U.S. by way of which Medicare plans were available in each county, we discovered that drugs can have a lot more variance in pricing than we even imagined. The most variable drug had over 6k unique prices across the country, with many in the 4k range. To statistically simplify, we took the median across all 30-day supply prices for each drug (9-digit NDC code) within each county. Note: 60-day and 90-day prices were also available, but were filtered out to simplify the overall analysis. A box plot of the top medications by total spend are shown below descending from the most spend to the least spend.  {@fig-pricevariance} This shows the variance in drug prices. Note that the absolute cost of the medication doesn’t correlate with the total nationwide spend for that medication. The drug with the top overall spend (Apixaban) is one of the cheapest at ~$10 per 30-day supply, while another drug in the top overall spend is VERY expensive at ~$26k per 30-day supply.


```{r}
#| label: fig-pricevariance
#| fig-cap: "Variance in price amongst the top drugs /n (descending by absolute spending) across the US"
#| warning: false
#| echo: false
#| message: false 

library(ggplot2)
library(dplyr)
library(scales)

box_plot_table <- readRDS("data/box_plot_table.rds")
spending_all_billions <- readRDS("data/spending_all_billions.rds")

# Make sure the key column names match for join
# Assuming spending_all_billions has 'Generic' and 'Spending_Billions' columns
# and box_plot_table has 'drug_name_clean' for the drug name

# Join spending info by drug name
box_plot_table <- box_plot_table %>%
  left_join(spending_all_billions, by = c("drug_name_clean" = "Generic")) %>%
  mutate(
    drug_label = paste0(drug_name_clean, " ($", round(Spending_Billions, 1), "B)")
  )

# Descending order of drugs by total spend
custom_order <- c(    "Apixaban", 
                      "Adalimumab", 
                      "Dulaglutide", 
                      "Lenalidomide", 
                      "Rivaroxaban",
                      "Empagliflozin", 
                      "Semaglutide", 
                      "Paliperidone Palmitate", 
                      "Etanercept",
                      "Insulin Aspart", 
                      "Ustekinumab", 
                      "Ibrutinib", 
                      "Tiotropium Bromide", 
                      "Liraglutide")

# Reorder the factor using the new label
box_plot_table <- box_plot_table %>%
  mutate(drug_label = factor(drug_label, levels = rev(paste0(custom_order, " ($", round(spending_all_billions$Spending_Billions[match(custom_order, spending_all_billions$Generic)], 1), "B)"))))

# Plot using the drug_label on the x-axis
ggplot(box_plot_table, aes(x = drug_label, y = UNIT_COST)) +
  geom_boxplot() + 
  labs(title = "Variance in price amongst the top drugs
(descending by total absolute spending between 2019-2023 )",
       x = "",
       y = "Price (USD, log scale)") +
  scale_y_log10(labels = comma) +
  theme_minimal() +
  coord_flip()  +
  theme(
    # axis.title.x = element_text(size = 16),  # increase x-axis label font size
    # axis.title.y = element_text(size = 16)   # increase y-axis label font size
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10)
  ) + 
  theme(
    plot.title.position = "plot",       # aligns title with plot area
    plot.title = element_text(hjust = 0) # hjust = 0 means left-align
  )

```

Not all these prices are available to every Medicare patient in the US. An individual’s price options depend on their county of residence. To further showcase the variance at a county level, below is a bar chart showing the number of medicare plans available within a sample state by county. (@fig-ORplans) 

```{r}
#| label: fig-ORplans
#| fig-cap: "Unique Medicare Plan Counts by Oregon County"
#| warning: false
#| echo: false
#| message: false
#| fig-height: 7 


# Load libraries
library(dplyr)
library(ggplot2)
library(forcats)

# Load data
or_contracts <- readRDS("data/or_medicare_plans_by_county.rds")

# Plot
ggplot(or_contracts, aes(x = fct_reorder(COUNTY, unique_contract_plans), y = unique_contract_plans)) +
  geom_bar(stat = "identity", fill = "darkgray") +
  coord_flip() +
  labs(
    title = "Unique Medicare Plan Counts by Oregon County",
    x = "County",
    y = "Unique Number of Medicare Plans Available to Residents",
  ) +
  theme_minimal(base_size = 12)

```

# Results

Our main hypothesis was that there is likely some demographic that is facing more hardship due to medication price inflation in counties with these demographics within the US. Can we use the demographics of a specific county along with the now know medication prices within said county to develop a model to predict the medication prices? If yes, we could in the short term advise people with specific medical condistions to move to counties with demographics that provide more favorable medication prices and long term influence the industry to fix such inequities. 

 An early concern in the development of this project was whether there would even be any price variation based on location.  A common misconception is that Medicare drug prices are the same across the US, given that Medicare is a public national medical insurance. The results were surprising. Drug prices do, in fact, vary significantly regionally, sometimes at the state level and sometimes at the county level. Semaglutide is one drug that stands out at the state level as shown in {@fig-map-semaglutide}. New York state has the lowest median 30-day supply price compared to every other stat in the country.

```{r}
#| label: fig-map-semaglutide
#| fig-cap: "Median Medicare Price for 30-day Supply of Semaglutide by US County"
#| warning: false
#| echo: false

chosen_drug = "Semaglutide"

# Load libraries
library(tigris)
library(sf)
library(ggplot2)
library(dplyr)

summary_table <- readRDS("data/map_data.rds")

# Use sf-compatible county shapefile (from tigris)
options(tigris_use_cache = TRUE)
counties_sf <- tigris::counties(cb = TRUE, class = "sf")

# Change county_code to FIPS style
# Choose drug of interest
summary_table2 <- summary_table %>%
  mutate(COUNTY_CODE = sprintf("%05s", COUNTY_CODE)) %>%
  filter(drug_name_clean == chosen_drug)

# Join median_cost to county map
counties_joined <- counties_sf %>%
  left_join(summary_table2, by = c("NAME" = "COUNTY", "STUSPS" = "STATE"))

# Define bounding box for continental US
bbox <- st_bbox(c(xmin = -125, xmax = -66, ymin = 23, ymax = 50), crs = st_crs(counties_joined))

# Crop the map
counties_cropped <- st_crop(counties_joined, bbox)

# Plot it
ggplot(counties_cropped) +
  geom_sf(aes(fill = median_price)) +
  scale_fill_viridis_c(option = "plasma", na.value = "grey90") +
  labs(
    title = paste0("Median Medicare Price for 30-day Supply of ",  chosen_drug, " by US County "),
    fill = "Median Cost"
  ) +
  theme_minimal(base_size = 10)
```

Liraglutide is unique in that it has a clear state-wide price impact like in New Mexico and Minnesota, but a county level price delta in some counties scattered across other states such as Nebraska, Oregon, Washington, Tennessee, Missouri, and Virginia. {@fig-map-liraglutide}

```{r}
#| label: fig-map-liraglutide
#| fig-cap: "Median Medicare Price for 30-day Supply of Liraglutide by US County"
#| warning: false
#| echo: false

chosen_drug = "Liraglutide"

# Load libraries
library(tigris)
library(sf)
library(ggplot2)
library(dplyr)

summary_table <- readRDS("data/map_data.rds")

# Use sf-compatible county shapefile (from tigris)
options(tigris_use_cache = TRUE)
counties_sf <- tigris::counties(cb = TRUE, class = "sf")

# Change county_code to FIPS style
# Choose drug of interest
summary_table2 <- summary_table %>%
  mutate(COUNTY_CODE = sprintf("%05s", COUNTY_CODE)) %>%
  filter(drug_name_clean == chosen_drug)

# Join median_cost to county map
counties_joined <- counties_sf %>%
  left_join(summary_table2, by = c("NAME" = "COUNTY", "STUSPS" = "STATE"))

# Define bounding box for continental US
bbox <- st_bbox(c(xmin = -125, xmax = -66, ymin = 23, ymax = 50), crs = st_crs(counties_joined))

# Crop the map
counties_cropped <- st_crop(counties_joined, bbox)

# Plot it
ggplot(counties_cropped) +
  geom_sf(aes(fill = median_price)) +
  scale_fill_viridis_c(option = "plasma", na.value = "grey90") +
  labs(
    title = paste0("Median Medicare Price for 30-day Supply of ",  chosen_drug, " by US County "),
    fill = "Median Cost"
  ) +
  theme_minimal(base_size = 10) + 
  theme(
    plot.title.position = "plot",       # aligns title with plot area
    plot.title = element_text(hjust = 0) # hjust = 0 means left-align
  )

```

Our team was surprised by what we observed once the median prices were applied to map plots.  There are clearly patterns here, but they vary geographically and the pattern is not the same with different drugs. To see maps for many more drugs, see this [shiny app](https://gpc1.shinyapps.io/shiny_maps_drug_median_price/). 

Given the pattern for medication prices across the maps, we started a deep dive into the demographics. Can we find any demographic data that can help predict thes prices? Our first dive was into the population. Do counties with a larger population have more Medicare plan options and this competition leads to lower drug prices? A scatter plot of the number of Medicare Plans available vs the population per county is shown below with a linear fit to show a trend line. {@fig-plans-vs-population} While there is a slight trend, it is a not a great fit. 

```{r}
#| label: fig-plans-vs-population
#| fig-cap: "Correlation between the number of Medicare Plan Options and Total Population by US County in 23Q4"
#| warning: false


library(tidyverse)
library(ggplot2)

summary_table = readRDS("data/summary_table_23Q4.rds")

summary_table2 <- summary_table %>%
  filter(!is.na(total_popE))

# Plot population vs
ggplot(summary_table2, aes(x = num_contract_plans, y = total_popE)) +
  geom_point(alpha = 0.6, color = "gray") +
  scale_y_log10(labels = scales::comma) + 
  geom_smooth(method = "lm", color = "black", se = FALSE, linetype = "dashed") +
  
  labs(
    title = "Number of Medicare Plan Options vs Total Population by US County in 23Q4",
    x = "Number of Medicare Plan Options",
    y = "Total Population (log scale)"
  ) +
  theme_minimal(base_size = 10) + 
  theme(
    plot.title.position = "plot",       # aligns title with plot area
    plot.title = element_text(hjust = 0) # hjust = 0 means left-align
  )

```

While there is a slight trend, it is not a great fit overall. The model is statistically significant (p-vaule < 0.05) and shows a moderate positive relationship (slope = 0.0195) between number of Medicare plans and population. But it's not a strong fit, two-thirds of the variation in population is left unexplained (adjusted R-squared = 0.3444), so we don’t wnat over-interpret this model as being predictive.
 
From here, we jumped into creating a model across all our demographics (age, education, gender, median income, and percent below poverty line). 

***ADD MACHINE LEARNING STUFF***

This regional variation underscores the importance of localized analysis. It also raises important questions about equity and access—particularly for beneficiaries in high-cost areas who may face greater financial burdens for the same treatments available at lower costs elsewhere. These disparities suggest that systemic inefficiencies or market imbalances may be at play, warranting further investigation and policy attention.

This regional variation underscores the importance of localized analysis. It also raises important questions about equity and access—particularly for beneficiaries in high-cost areas who may face greater financial burdens for the same treatments available at lower costs elsewhere. These disparities suggest that systemic inefficiencies or market imbalances may be at play, warranting further investigation and policy attention.



# Conclusions

Our analysis reveals significant geographic disparities in Medicare Part D drug pricing across the United States. While our data does not conclusively demonstrate that these pricing variations disproportionately affect any single demographic group, the inconsistencies raise serious concerns about the effectiveness and equity of Medicare’s price negotiation mechanisms. The observed variation suggests that drug costs could be more uniformly regulated, pointing to inefficiencies in the current system.

For many Medicare beneficiaries—particularly older adults and individuals with limited resources—the burden of navigating complex plan options to secure affordable coverage is substantial. Despite the availability of plan finder tools and licensed advisors, the process remains daunting for a population that the program is intended to support. This complexity undermines the accessibility and fairness of Medicare Part D.  

The Inflation Reduction Act of 2022 marked a pivotal step toward addressing unsustainable drug pricing. Regulatory intervention, as demonstrated by the U.S. Department of Health and Human Services (HHS) and the CMS [@cms2025negotiation], has shown potential to curb excessive price increases. In December 2024, CMS [@cms2024inflationrebate] announced cost savings for 64 drugs whose prices had outpaced inflation—an encouraging sign of progress. However, the full impact of these measures remains uncertain. Much of the projected savings will not materialize until 2026, and their effectiveness will depend on pharmaceutical industry responses, future pricing trends, and the extent to which affected medications are utilized.

To promote greater equity and transparency, federal and state policymakers could collaborate to ensure that the lowest negotiated drug prices are made broadly accessible, rather than confined to specific plans or contracts. There is a clear opportunity to advance price normalization and improve the transparency of treatment costs, which would better serve Medicare beneficiaries and strengthen the integrity of the program.

Price normalization across Medicare Part D plans could have far-reaching benefits beyond the immediate Medicare population. By reducing regional and plan-based disparities, normalization would help create a more predictable and equitable pricing environment for all stakeholders, including providers, pharmacies, and insurers. It could also reduce administrative overhead associated with managing complex pricing structures and improve the efficiency of healthcare delivery.

Normalized pricing could help curb overall healthcare spending by discouraging price inflation and promoting competitive pricing among pharmaceutical manufacturers. When drug prices are consistent and transparent, it becomes easier for policymakers and researchers to evaluate cost-effectiveness, identify inefficiencies, and implement targeted reforms. This could lead to better resource allocation and improved public health outcomes.



# References

:::{#refs}
:::


